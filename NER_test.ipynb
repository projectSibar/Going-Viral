{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NER_test.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO3cvHSGuA1tdBkktQNcijC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RXCU7zTrpQdT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626913702490,"user_tz":-540,"elapsed":6,"user":{"displayName":"이화연","photoUrl":"","userId":"17940327460450266658"}},"outputId":"befb14b4-0a98-4a81-dc1e-5e1ad8816eac"},"source":["#나의 구글 드라이브를 구글 본사 서버와 연결하는 작업\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ta0_LEUppZLf","executionInfo":{"status":"ok","timestamp":1626913717276,"user_tz":-540,"elapsed":276,"user":{"displayName":"이화연","photoUrl":"","userId":"17940327460450266658"}},"outputId":"7175e7bd-afb7-4c19-9b84-8bb5ecc2433d"},"source":["#현재 작업 폴더 nip로 경로 이동하기\n","%cd \"/content/drive/My Drive/nlp/pytorch-bert-crf-ner\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/nlp/pytorch-bert-crf-ner\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kCCifYG5thXm","executionInfo":{"status":"ok","timestamp":1626913720861,"user_tz":-540,"elapsed":349,"user":{"displayName":"이화연","photoUrl":"","userId":"17940327460450266658"}}},"source":["# !pip install -r requirements.txt"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuqCGWsjpnwQ","executionInfo":{"status":"ok","timestamp":1626913790382,"user_tz":-540,"elapsed":61296,"user":{"displayName":"이화연","photoUrl":"","userId":"17940327460450266658"}},"outputId":"3d5ea2c7-d601-4854-cad7-6555fa52d5c3"},"source":["# 필요한 라이브러리 설치\n","!pip install transformers\n","!pip install pytorch_transformers\n","!pip install gluonnlp\n","!pip install --upgrade mxnet-cu100\n","!pip install TorchCRF\n","!pip install konlpy"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 8.1 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 41.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 25.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n","Collecting pytorch_transformers\n","  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n","\u001b[K     |████████████████████████████████| 176 kB 7.9 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 41.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.9.0+cu102)\n","Collecting boto3\n","  Downloading boto3-1.18.4-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 72.6 MB/s \n","\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.0.45)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.9 MB/s \n","\u001b[?25hCollecting botocore<1.22.0,>=1.21.4\n","  Downloading botocore-1.21.4-py3-none-any.whl (7.7 MB)\n","\u001b[K     |████████████████████████████████| 7.7 MB 49.7 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 74.7 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.4->boto3->pytorch_transformers) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.4->boto3->pytorch_transformers) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 66.1 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2021.5.30)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, boto3, pytorch-transformers\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.18.4 botocore-1.21.4 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sentencepiece-0.1.96 urllib3-1.25.11\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.23)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595726 sha256=04f7c0c03188b5886a75b9fcac8945dee2cda0b6810edb18bc6b7be1b19dd02a\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Collecting mxnet-cu100\n","  Downloading mxnet_cu100-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (352.6 MB)\n","\u001b[K     |████████████████████████████████| 352.6 MB 13 kB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu100) (2.23.0)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu100) (1.19.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (1.25.11)\n","Installing collected packages: graphviz, mxnet-cu100\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-cu100-1.8.0.post0\n","Collecting TorchCRF\n","  Downloading TorchCRF-1.1.0-py3-none-any.whl (5.2 kB)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from TorchCRF) (1.9.0+cu102)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from TorchCRF) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->TorchCRF) (3.7.4.3)\n","Installing collected packages: TorchCRF\n","Successfully installed TorchCRF-1.1.0\n","Collecting konlpy\n","  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 120 kB/s \n","\u001b[?25hCollecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 59.5 MB/s \n","\u001b[?25hCollecting beautifulsoup4==4.6.0\n","  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 7.0 MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PeceC2Dvs4Lc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3NXW4f6-tGy_","executionInfo":{"status":"ok","timestamp":1626914163501,"user_tz":-540,"elapsed":4005,"user":{"displayName":"이화연","photoUrl":"","userId":"17940327460450266658"}}},"source":["from TorchCRF import CRF"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8XjEltApx12","executionInfo":{"status":"ok","timestamp":1626914179134,"user_tz":-540,"elapsed":12343,"user":{"displayName":"이화연","photoUrl":"","userId":"17940327460450266658"}},"outputId":"4c4f777a-dece-4969-eee7-6074ce329f17"},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import argparse\n","import numpy as np\n","import logging\n","import random\n","import pickle\n","import json\n","import os\n","from pathlib import Path\n","\n","import torch\n","from pytorch_transformers import AdamW, WarmupLinearSchedule\n","from torch.utils.tensorboard import SummaryWriter # from tensorboardX import SummaryWriter\n","from torch.utils.data import DataLoader\n","from torch import nn, optim\n","from tqdm import tqdm, trange\n","from data_utils.utils import CheckpointManager, SummaryManager\n","from model.net import KobertCRF\n","from model.utils import Config\n","\n","from data_utils.ner_dataset import NamedEntityRecognitionDataset, NamedEntityRecognitionFormatter\n","from data_utils.vocab_tokenizer import Vocabulary, Tokenizer\n","from data_utils.pad_sequence import keras_pad_fn\n","from gluonnlp.data import SentencepieceTokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","from kobert.utils import get_tokenizer\n","from sklearn.metrics import classification_report"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n","  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vIYyT38l0rG-","colab":{"base_uri":"https://localhost:8080/","height":208},"executionInfo":{"status":"error","timestamp":1626914192495,"user_tz":-540,"elapsed":1588,"user":{"displayName":"이화연","photoUrl":"","userId":"17940327460450266658"}},"outputId":"e31777d7-645b-466c-e0df-c8f3f234a3b0"},"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","logger = logging.getLogger(__name__)\n","\n","def set_seed(seed=100):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    n_gpu = torch.cuda.device_count()\n","    if n_gpu > 0:\n","        torch.cuda.manual_seed_all(seed)\n","\n","def main(parser):\n","    # Config\n","    args = parser.parse_args()\n","    data_dir = Path(args.data_dir)\n","    model_dir = Path(args.model_dir)\n","\n","    # data_config = Config(json_path=data_dir / 'config.json')\n","    model_config = Config(json_path=model_dir / 'config.json')\n","\n","    # Vocab & Tokenizer\n","    tok_path = get_tokenizer() # ./tokenizer_78b3253a26.model\n","    ptr_tokenizer = SentencepieceTokenizer(tok_path)\n","\n","    _, vocab_of_gluonnlp = get_pytorch_kobert_model()\n","    token_to_idx = vocab_of_gluonnlp.token_to_idx\n","\n","    model_config.vocab_size = len(token_to_idx)\n","    vocab = Vocabulary(token_to_idx=token_to_idx)\n","\n","    print(\"len(token_to_idx): \", len(token_to_idx))\n","    with open(model_dir / \"token2idx_vocab.json\", 'w', encoding='utf-8') as f:\n","        json.dump(token_to_idx, f, ensure_ascii=False, indent=4)\n","\n","    # save vocab & tokenizer\n","    with open(model_dir / \"vocab.pkl\", 'wb') as f:\n","        pickle.dump(vocab, f)\n","\n","    # load vocab & tokenizer\n","    with open(model_dir / \"vocab.pkl\", 'rb') as f:\n","        vocab = pickle.load(f)\n","\n","    tokenizer = Tokenizer(vocab=vocab, split_fn=ptr_tokenizer, pad_fn=keras_pad_fn, maxlen=model_config.maxlen)\n","    ner_formatter = NamedEntityRecognitionFormatter(vocab=vocab, tokenizer=tokenizer, maxlen=model_config.maxlen, model_dir=model_dir)\n","\n","    # Train & Val Datasets\n","    cwd = Path.cwd()\n","    data_in = cwd / \"data_in\"\n","    train_data_dir = data_in / \"NER-master\" / \"말뭉치 - 형태소_개체명\"\n","    tr_ds = NamedEntityRecognitionDataset(train_data_dir=train_data_dir, model_dir=model_dir)\n","    tr_ds.set_transform_fn(transform_source_fn=ner_formatter.transform_source_fn, transform_target_fn=ner_formatter.transform_target_fn)\n","    tr_dl = DataLoader(tr_ds, batch_size=model_config.batch_size, shuffle=True, num_workers=4, drop_last=False)\n","\n","    val_data_dir = data_in / \"NER-master\" / \"validation_set\"\n","    val_ds = NamedEntityRecognitionDataset(train_data_dir=val_data_dir, model_dir=model_dir)\n","    val_ds.set_transform_fn(transform_source_fn=ner_formatter.transform_source_fn, transform_target_fn=ner_formatter.transform_target_fn)\n","    val_dl = DataLoader(val_ds, batch_size=model_config.batch_size, shuffle=True, num_workers=4, drop_last=False)\n","\n","    # Model\n","    model = KobertCRF(config=model_config, num_classes=len(tr_ds.ner_to_index))\n","    model.to(device)\n","    model.train()\n","\n","    # optim\n","    train_examples_len = len(tr_ds)\n","    val_examples_len = len(val_ds)\n","    print(\"num of train: {}, num of val: {}\".format(train_examples_len, val_examples_len))\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","\n","    # num_train_optimization_steps = int(train_examples_len / model_config.batch_size / model_config.gradient_accumulation_steps) * model_config.epochs\n","    t_total = len(tr_dl) // model_config.gradient_accumulation_steps * model_config.epochs\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=model_config.learning_rate, eps=model_config.adam_epsilon)\n","    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=model_config.warmup_steps, t_total=t_total)\n","\n","    n_gpu = torch.cuda.device_count()\n","    # if n_gpu > 1:\n","    #     model = torch.nn.DataParallel(model)\n","\n","    # save\n","    tb_writer = SummaryWriter('{}/runs'.format(model_dir))\n","    checkpoint_manager = CheckpointManager(model_dir)\n","    summary_manager = SummaryManager(model_dir)\n","\n","    # Train!\n","    logger.info(\"***** Running training *****\")\n","    logger.info(\"  Num examples = %d\", len(tr_ds))\n","    logger.info(\"  Num Epochs = %d\", model_config.epochs)\n","    logger.info(\"  Instantaneous batch size per GPU = %d\", model_config.batch_size)\n","    logger.info(\"  Gradient Accumulation steps = %d\", model_config.gradient_accumulation_steps)\n","    logger.info(\"  Total optimization steps = %d\", t_total)\n","\n","    global_step = 0\n","    tr_loss, logging_loss = 0.0, 0.0\n","    best_dev_acc, best_dev_loss = 0.0, 99999999999.0\n","    best_steps = 0\n","    model.zero_grad()\n","    set_seed()  # Added here for reproductibility (even between python 2 and 3)\n","\n","    # Train\n","    train_iterator = trange(int(model_config.epochs), desc=\"Epoch\")\n","    for _epoch, _ in enumerate(train_iterator):\n","        epoch_iterator = tqdm(tr_dl, desc=\"Iteration\")\n","        epoch = _epoch\n","        for step, batch in enumerate(epoch_iterator):\n","            model.train()\n","            x_input, token_type_ids, y_real = map(lambda elm: elm.to(device), batch)\n","            log_likelihood, sequence_of_tags = model(x_input, token_type_ids, y_real)\n","\n","            # loss: negative log-likelihood\n","            loss = -1 * log_likelihood\n","\n","            if n_gpu > 1:\n","                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n","            if model_config.gradient_accumulation_steps > 1:\n","                loss = loss / model_config.gradient_accumulation_steps\n","\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), model_config.max_grad_norm)\n","            tr_loss += loss.item()\n","\n","            if (step + 1) % model_config.gradient_accumulation_steps == 0:\n","                optimizer.step()\n","                scheduler.step()  # Update learning rate schedule\n","                model.zero_grad()\n","                global_step += 1\n","\n","                with torch.no_grad():\n","                    sequence_of_tags = torch.tensor(sequence_of_tags).to(device)\n","                    mb_acc = (sequence_of_tags == y_real).float()[y_real != vocab.PAD_ID].mean()\n","\n","                tr_acc = mb_acc.item()\n","                tr_loss_avg = tr_loss / global_step\n","                tr_summary = {'loss': tr_loss_avg, 'acc': tr_acc}\n","\n","                # if step % 50 == 0:\n","                print('epoch : {}, global_step : {}, tr_loss: {:.3f}, tr_acc: {:.2%}'.format(epoch + 1, global_step, tr_summary['loss'], tr_summary['acc']))\n","\n","                # training & evaluation log\n","                if model_config.logging_steps > 0 and global_step % model_config.logging_steps == 0:\n","                    if model_config.evaluate_during_training:  # Only evaluate when single GPU otherwise metrics may not average well\n","                        eval_summary, list_of_y_real, list_of_pred_tags = evaluate(model, val_dl)\n","                        tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n","                        tb_writer.add_scalars('loss', {'train': (tr_loss - logging_loss) / model_config.logging_steps, 'val': eval_summary[\"eval_loss\"]}, global_step)\n","                        tb_writer.add_scalars('acc', {'train': tr_acc, 'val': eval_summary[\"eval_acc\"]}, global_step)\n","                        print(\"eval acc: {}, loss: {}, global steps: {}\".format(eval_summary['eval_acc'], eval_summary['eval_loss'], global_step))\n","                    print(\"Average loss: {} at global step: {}\".format((tr_loss - logging_loss) / model_config.logging_steps, global_step))\n","                    logging_loss = tr_loss\n","\n","                # save model\n","                if model_config.save_steps > 0 and global_step % model_config.save_steps == 0:\n","                    eval_summary, list_of_y_real, list_of_pred_tags = evaluate(model, val_dl)\n","\n","                    # Save model checkpoint\n","                    output_dir = os.path.join(model_config.output_dir, 'epoch-{}'.format(epoch + 1))\n","                    if not os.path.exists(output_dir):\n","                        os.makedirs(output_dir)\n","                    print(\"Saving model checkpoint to %s\", output_dir)\n","                    state = {'global_step': global_step + 1,\n","                             'model_state_dict': model.state_dict(),\n","                             'opt_state_dict': optimizer.state_dict()}\n","                    summary = {'train': tr_summary, 'eval': eval_summary}\n","                    summary_manager.update(summary)\n","                    print(\"summary: \", summary)\n","                    summary_manager.save('summary.json')\n","\n","                    # Save\n","                    is_best = eval_summary[\"eval_acc\"] >= best_dev_acc  # acc 기준 (원래는 train_acc가 아니라 val_acc로 해야)\n","                    if is_best:\n","                        best_dev_acc = eval_summary[\"eval_acc\"]\n","                        best_dev_loss = eval_summary[\"eval_loss\"]\n","                        best_steps = global_step\n","                        # if args.do_test:\n","                        # results_test = evaluate(model, test_dl, test=True)\n","                        # for key, value in results_test.items():\n","                        #     tb_writer.add_scalar('test_{}'.format(key), value, global_step)\n","                        # logger.info(\"test acc: %s, loss: %s, global steps: %s\", str(eval_summary['eval_acc']), str(eval_summary['eval_loss']), str(global_step))\n","\n","                        checkpoint_manager.save_checkpoint(state, 'best-epoch-{}-step-{}-acc-{:.3f}.bin'.format(epoch + 1, global_step, best_dev_acc))\n","                        print(\"Saving model checkpoint as best-epoch-{}-step-{}-acc-{:.3f}.bin\".format(epoch + 1, global_step, best_dev_acc))\n","\n","                        # print classification report and save confusion matrix\n","                        cr_save_path = model_dir / 'best-epoch-{}-step-{}-acc-{:.3f}-cr.csv'.format(epoch + 1, global_step, best_dev_acc)\n","                        cm_save_path = model_dir / 'best-epoch-{}-step-{}-acc-{:.3f}-cm.png'.format(epoch + 1, global_step, best_dev_acc)\n","                        save_cr_and_cm(val_dl, list_of_y_real, list_of_pred_tags, cr_save_path=cr_save_path, cm_save_path=cm_save_path)\n","                    else:\n","                        torch.save(state, os.path.join(output_dir, 'model-epoch-{}-step-{}-acc-{:.3f}.bin'.format(epoch + 1, global_step, eval_summary[\"eval_acc\"])))\n","                        print(\"Saving model checkpoint as model-epoch-{}-step-{}-acc-{:.3f}.bin\".format(epoch + 1, global_step, eval_summary[\"eval_acc\"]))\n","\n","    tb_writer.close()\n","    print(\"global_step = {}, average loss = {}\".format(global_step, tr_loss / global_step))\n","\n","    return global_step, tr_loss / global_step, best_steps\n","\n","\n","def evaluate(model, val_dl, prefix=\"NER\"):\n","    \"\"\" evaluate accuracy and return result \"\"\"\n","    results = {}\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","    # Eval!\n","    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","\n","    list_of_y_real = []\n","    list_of_pred_tags = []\n","    count_correct = 0\n","    total_count = 0\n","\n","    for batch in tqdm(val_dl, desc=\"Evaluating\"):\n","        model.train()\n","        x_input, token_type_ids, y_real = map(lambda elm: elm.to(device), batch)\n","        with torch.no_grad():\n","            inputs = {'input_ids': x_input,\n","                      'token_type_ids': token_type_ids,\n","                      'tags': y_real}\n","            log_likelihood, sequence_of_tags = model(**inputs)\n","\n","            eval_loss += -1 * log_likelihood.float().item()\n","        nb_eval_steps += 1\n","\n","        y_real = y_real.to('cpu')\n","        sequence_of_tags = torch.tensor(sequence_of_tags).to('cpu')\n","        count_correct += (sequence_of_tags == y_real).float()[y_real != 2].sum()  # 0,1,2,3 -> [CLS], [SEP], [PAD], [MASK] index\n","        total_count += len(y_real[y_real != 2])\n","\n","        for seq_elm in y_real.tolist():\n","            list_of_y_real += seq_elm\n","\n","        for seq_elm in sequence_of_tags.tolist():\n","            list_of_pred_tags += seq_elm\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    acc = (count_correct / total_count).item()  # tensor -> float\n","    result = {\"eval_acc\": acc, \"eval_loss\": eval_loss}\n","    results.update(result)\n","\n","    return results, list_of_y_real, list_of_pred_tags\n","\n","\n","import operator\n","import pandas as pd\n","def save_cr_and_cm(val_dl, list_of_y_real, list_of_pred_tags, cr_save_path=\"classification_report.csv\", cm_save_path=\"confusion_matrix.png\"):\n","    \"\"\" print classification report and confusion matrix \"\"\"\n","\n","    # target_names = val_dl.dataset.ner_to_index.keys()\n","    sorted_ner_to_index = sorted(val_dl.dataset.ner_to_index.items(), key=operator.itemgetter(1))\n","    target_names = []\n","    for ner_tag, index in sorted_ner_to_index:\n","        if ner_tag in ['[CLS]', '[SEP]', '[PAD]', '[MASK]', 'O']:\n","            continue\n","        else:\n","            target_names.append(ner_tag)\n","\n","    label_index_to_print = list(range(5, 25))  # ner label indice except '[CLS]', '[SEP]', '[PAD]', '[MASK]' and 'O' tag\n","    print(classification_report(y_true=list_of_y_real, y_pred=list_of_pred_tags, target_names=target_names, labels=label_index_to_print, digits=4))\n","    cr_dict = classification_report(y_true=list_of_y_real, y_pred=list_of_pred_tags, target_names=target_names, labels=label_index_to_print, digits=4, output_dict=True)\n","    df = pd.DataFrame(cr_dict).transpose()\n","    df.to_csv(cr_save_path)\n","    np.set_printoptions(precision=2)\n","    plot_confusion_matrix(y_true=list_of_y_real, y_pred=list_of_pred_tags, classes=target_names, labels=label_index_to_print, normalize=False, title='Confusion matrix, without normalization')\n","    plt.savefig(cm_save_path)\n","    # plt.show()\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils.multiclass import unique_labels\n","def plot_confusion_matrix(y_true, y_pred, classes, labels,\n","                          normalize=False,\n","                          title=None,\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if not title:\n","        if normalize:\n","            title = 'Normalized confusion matrix'\n","        else:\n","            title = 'Confusion matrix, without normalization'\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=labels)\n","    # Only use the labels that appear in the data\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    # --- plot 크기 조절 --- #\n","    plt.rcParams['savefig.dpi'] = 200\n","    plt.rcParams['figure.dpi'] = 200\n","    plt.rcParams['figure.figsize'] = [20, 20]  # plot 크기\n","    plt.rcParams.update({'font.size': 10})\n","    # --- plot 크기 조절 --- #\n","\n","    fig, ax = plt.subplots()\n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","\n","    # --- bar 크기 조절 --- #\n","    from mpl_toolkits.axes_grid1 import make_axes_locatable\n","    divider = make_axes_locatable(ax)\n","    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n","    plt.colorbar(im, cax=cax)\n","    # --- bar 크기 조절 --- #\n","    # ax.figure.colorbar(im, ax=ax)\n","\n","    # We want to show all ticks...\n","    ax.set(xticks=np.arange(cm.shape[1]),\n","           yticks=np.arange(cm.shape[0]),\n","           # ... and label them with the respective list entries\n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel='True label',\n","           xlabel='Predicted label')\n","\n","    # Rotate the tick labels and set their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","             rotation_mode=\"anchor\")\n","\n","    # Loop over data dimensions and create text annotations.\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, format(cm[i, j], fmt),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    fig.tight_layout()\n","    return ax\n","\n","\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--data_dir', default='data_in', help=\"Directory containing config.json of data\")\n","    parser.add_argument('--model_dir', default='experiments/base_model_with_crf_val', help=\"Directory containing config.json of model\")\n","\n","    main(parser)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["usage: ipykernel_launcher.py [-h] [--data_dir DATA_DIR]\n","                             [--model_dir MODEL_DIR]\n","ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-252b79a1-4a57-4183-9395-d889274bdd69.json\n"],"name":"stderr"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]}]}